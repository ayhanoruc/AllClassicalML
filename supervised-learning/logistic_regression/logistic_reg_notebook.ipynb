{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_iris()\n",
    "data = dataset.data\n",
    "target = dataset.target\n",
    "df = pd.DataFrame(data, columns=dataset.feature_names)\n",
    "df[\"target\"] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "120                6.9               3.2                5.7               2.3   \n",
       "77                 6.7               3.0                5.0               1.7   \n",
       "15                 5.7               4.4                1.5               0.4   \n",
       "\n",
       "     target  \n",
       "120       2  \n",
       "77        1  \n",
       "15        0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(20).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  0  0]\n",
      " [ 0  9  1]\n",
      " [ 0  0 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.90      0.95        10\n",
      "           2       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('target',axis=1)\n",
    "y = df.target\n",
    "# Load and preprocess data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize and train the logistic regression model\n",
    "model = LogisticRegression(multi_class='multinomial', max_iter=10000, penalty='l2')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_threshold(model, X, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Predict class labels based on a specified threshold.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained logistic regression model\n",
    "    - X: Input features for prediction\n",
    "    - threshold: Classification threshold (default is 0.5)\n",
    "\n",
    "    Returns:\n",
    "    - Predicted class labels based on the specified threshold\n",
    "    \"\"\"\n",
    "    # First, get predicted probabilities for each class\n",
    "    y_probabilities = model.predict_proba(X)\n",
    "\n",
    "    # Apply the new threshold to classify instances\n",
    "    y_pred = (y_probabilities[:, 1] > threshold).astype(int)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**L1 Regularization (Lasso Regression)**\n",
      "\n",
      "L1 regularization, also known as Lasso (Least Absolute Shrinkage and Selection Operator) regression, adds the sum of the absolute values of the coefficients as a penalty term to the loss function.\n",
      "\n",
      "- *Objective Function:*\n",
      "  J(θ) = MSE(θ) + α ∑_{i=1}^{n} |θ_i|\n",
      "\n",
      "- *Effect:*\n",
      "  - Encourages sparsity in the model by driving some coefficients to exactly zero.\n",
      "  - Useful for feature selection when dealing with high-dimensional data.\n",
      "\n",
      "\n",
      "**L2 Regularization (Ridge Regression)**\n",
      "\n",
      "L2 regularization, or Ridge regression, adds the sum of the squared values of the coefficients as a penalty term to the loss function.\n",
      "\n",
      "- *Objective Function:*\n",
      "  J(θ) = MSE(θ) + α ∑_{i=1}^{n} θ_i^2\n",
      "\n",
      "- *Effect:*\n",
      "  - Controls the magnitude of the coefficients, preventing them from becoming too large.\n",
      "  - Useful for mitigating multicollinearity.\n",
      "\n",
      "\n",
      "**Elastic Net**\n",
      "\n",
      "Elastic Net is a combination of L1 and L2 regularization, blending both penalties in the loss function.\n",
      "\n",
      "- *Objective Function:*\n",
      "  J(θ) = MSE(θ) + rα ∑_{i=1}^{n} |θ_i| + (1-r)α/2 ∑_{i=1}^{n} θ_i^2\n",
      "\n",
      "- *Effect:*\n",
      "  - Combines the sparsity-inducing property of L1 regularization with the scale-controlling property of L2 regularization.\n",
      "  - Suitable when dealing with correlated features and feature selection is desirable.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "l1_regularization_info = \"\"\"\n",
    "**L1 Regularization (Lasso Regression)**\n",
    "\n",
    "L1 regularization, also known as Lasso (Least Absolute Shrinkage and Selection Operator) regression, adds the sum of the absolute values of the coefficients as a penalty term to the loss function.\n",
    "\n",
    "- *Objective Function:*\n",
    "  J(θ) = MSE(θ) + α ∑_{i=1}^{n} |θ_i|\n",
    "\n",
    "- *Effect:*\n",
    "  - Encourages sparsity in the model by driving some coefficients to exactly zero.\n",
    "  - Useful for feature selection when dealing with high-dimensional data.\n",
    "\"\"\"\n",
    "\n",
    "l2_regularization_info = \"\"\"\n",
    "**L2 Regularization (Ridge Regression)**\n",
    "\n",
    "L2 regularization, or Ridge regression, adds the sum of the squared values of the coefficients as a penalty term to the loss function.\n",
    "\n",
    "- *Objective Function:*\n",
    "  J(θ) = MSE(θ) + α ∑_{i=1}^{n} θ_i^2\n",
    "\n",
    "- *Effect:*\n",
    "  - Controls the magnitude of the coefficients, preventing them from becoming too large.\n",
    "  - Useful for mitigating multicollinearity.\n",
    "\"\"\"\n",
    "\n",
    "elastic_net_info = \"\"\"\n",
    "**Elastic Net**\n",
    "\n",
    "Elastic Net is a combination of L1 and L2 regularization, blending both penalties in the loss function.\n",
    "\n",
    "- *Objective Function:*\n",
    "  J(θ) = MSE(θ) + rα ∑_{i=1}^{n} |θ_i| + (1-r)α/2 ∑_{i=1}^{n} θ_i^2\n",
    "\n",
    "- *Effect:*\n",
    "  - Combines the sparsity-inducing property of L1 regularization with the scale-controlling property of L2 regularization.\n",
    "  - Suitable when dealing with correlated features and feature selection is desirable.\n",
    "\"\"\"\n",
    "\n",
    "print(l1_regularization_info)\n",
    "print(l2_regularization_info)\n",
    "print(elastic_net_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization = Loss Function + Penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
